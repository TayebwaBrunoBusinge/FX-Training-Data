{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "m5 = []\n",
    "m15 = []\n",
    "m30 = []\n",
    "h1 = []\n",
    "h4 = []\n",
    "d1 = []\n",
    "quarter_hours = [\"15\", \"45\"]\n",
    "four_hours = [\"04:00\", \"08:00\", \"12:00\", \"16:00\", \"20:00\"]\n",
    "timeframes = [m5, m15, m30, h1, h4, d1]\n",
    "\n",
    "timeframe_names = [\"m5\", \"m15\", \"m30\", \"h1\", \"h4\", \"d1\"]\n",
    "symbols = [\n",
    "    \"GBPUSD_2021_m1.csv\",\n",
    "    \"GBPUSD_2020_m1.csv\",\n",
    "    \"GBPUSD_2019_m1.csv\",\n",
    "    \"GBPJPY_2021_m1.csv\",\n",
    "    \"GBPJPY_2020_m1.csv\",\n",
    "    \"GBPJPY_2019_m1.csv\",\n",
    "    \"EURUSD_2021_m1.csv\",\n",
    "    \"EURUSD_2020_m1.csv\",\n",
    "    \"EURUSD_2019_m1.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "def processSymbol(symbol):\n",
    "    symbol_path = (\n",
    "        \"/media/bruno/f71fc4fd-abcd-4a4b-9fb1-6a8899041c1c/FX-Training-Data/ALL/\"\n",
    "        + str(symbol)\n",
    "    )\n",
    "    base_data = np.array(\n",
    "        pd.read_csv(\n",
    "            symbol_path,\n",
    "            header=None,\n",
    "        )\n",
    "    )\n",
    "    return base_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTimeframeData(base_data):\n",
    "    # print(\"making timeframe data\")\n",
    "\n",
    "    for i in range(len(base_data)):\n",
    "\n",
    "        if str(base_data[i][1]).endswith(\"0\"):\n",
    "            m5.append(i)\n",
    "\n",
    "            if str(base_data[i][1]).endswith(\"00\"):\n",
    "                h1.append(i)\n",
    "                m30.append(i)\n",
    "                m15.append(i)\n",
    "                if str(base_data[i][1]) in four_hours:\n",
    "                    h4.append(i)\n",
    "                    continue\n",
    "                if str(base_data[i][1]) == \"00:00\":\n",
    "                    d1.append(i)\n",
    "                    h4.append(i)\n",
    "                    continue\n",
    "            elif str(base_data[i][1]).endswith(\"30\"):\n",
    "                m30.append(i)\n",
    "                m15.append(i)\n",
    "                continue\n",
    "\n",
    "        elif str(base_data[i][1]).endswith(\"5\"):\n",
    "            m5.append(i)\n",
    "            if str(base_data[i][1]).endswith(\"45\") or str(base_data[i][1]).endswith(\n",
    "                \"15\"\n",
    "            ):\n",
    "                m15.append(i)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Row:\n",
    "    def __init__(self, date, time, p_open, p_high, p_low, p_close, volume, st_bullish, st_bearish, st_neutral, ss_asia, ss_europe, ss_newyork):\n",
    "        self.date = date\n",
    "        self.time = time\n",
    "        self.p_open = float(p_open)\n",
    "        self.p_high = float(p_high)\n",
    "        self.p_low = float(p_low)\n",
    "        self.p_close = float(p_close)\n",
    "        self.volume = int(volume)\n",
    "        self.st_bullish = int(st_bullish)\n",
    "        self.st_bearish = int(st_bearish)\n",
    "        self.st_neutral = int(st_neutral)\n",
    "        self.ss_asia = int(ss_asia)\n",
    "        self.ss_europe = int(ss_europe)\n",
    "        self.ss_newyork = int(ss_newyork)\n",
    "\n",
    "    def makeRecord(self):\n",
    "        return list(\n",
    "            [\n",
    "                self.date,\n",
    "                self.time,\n",
    "                self.p_open,\n",
    "                self.p_high,\n",
    "                self.p_low,\n",
    "                self.p_close,\n",
    "                self.volume,\n",
    "                self.st_bullish,\n",
    "                self.st_bearish,\n",
    "                self.st_neutral,\n",
    "                self.ss_asia,\n",
    "                self.ss_europe,\n",
    "                self.ss_newyork\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMax(base_data, column_index, start, stop):\n",
    "    values = list()\n",
    "    for i in range(start, stop):\n",
    "        values.append(float(base_data[i][column_index]))\n",
    "    return max(values)\n",
    "\n",
    "\n",
    "def getMin(base_data, column_index, start, stop):\n",
    "    values = list()\n",
    "    for i in range(start, stop):\n",
    "        values.append(float(base_data[i][column_index]))\n",
    "    return min(values)\n",
    "\n",
    "\n",
    "def getSum(base_data, column_index, start, stop):\n",
    "    values = list()\n",
    "    for i in range(start, stop):\n",
    "        values.append(float(base_data[i][column_index]))\n",
    "    return sum(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that you have lists of positions for each time interval, use those to recalculate OHLCVS(indices 2,3,4,5,6,7)\n",
    "<!-- for each index listed in h1,h4,etc look for a corresponding element in base_data -->\n",
    "<!-- open = same open as that index -->\n",
    "<!-- p_close = p_close of index prior to interval index -->\n",
    "<!-- p_high = highest value base_data[index][3] in range(curr_interval_index, next_interval_index) -->\n",
    "<!-- p_low =  lowest value base_data[index][3] in range(curr_interval_index, next_interval_index)-->\n",
    "<!-- volume = sum of base_data[index][6] in range(curr_interval_index, next_interval_index) -->\n",
    "<!-- state = [0 if open==p_close, 1 if p_close>open, -1 if p_close<open] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "asia_start = time.strptime(\"02:00\", \"%H:%M\")\n",
    "asia_end = time.strptime(\"11:00\", \"%H:%M\")\n",
    "print((asia_end.tm_hour))\n",
    "europe_start = time.strptime(\"10:00\", \"%H:%M\")\n",
    "europe_end = time.strptime(\"19:00\", \"%H:%M\")\n",
    "newyork_start = time.strptime(\"15:00\", \"%H:%M\")\n",
    "newyork_end = time.strptime(\"23:00\", \"%H:%M\")\n",
    "\n",
    "\n",
    "def processCsv(base_data, timeframe, symbol):\n",
    "    data = [\n",
    "        [\n",
    "            \"date\",\n",
    "            \"time\",\n",
    "            \"p_open\",\n",
    "            \"p_high\",\n",
    "            \"p_low\",\n",
    "            \"p_close\",\n",
    "            \"volume\",\n",
    "            \"st_bullish\",\n",
    "            \"st_bearish\",\n",
    "            \"st_neutral\",\n",
    "            \"ss_asia\",\n",
    "            \"ss_europe\",\n",
    "            \"ss_newyork\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    for i in range(len(timeframe)):\n",
    "        # if i == 0:\n",
    "        #     # data = [[\"date\", \"time\", \"open\", \"p_high\", \"p_low\", \"p_close\", \"volume\", \"state\"]]\n",
    "        #     print(\"starting afresh\")\n",
    "        if (i + 1) == len(timeframe):\n",
    "            data = pd.DataFrame(data)\n",
    "            newCsv_name = (\n",
    "                \"Sorted/\"\n",
    "                + symbol[:6]\n",
    "                + \"/\"\n",
    "                + symbol[:11]\n",
    "                + \"_\"\n",
    "                + str(timeframe_names[timeframes.index(timeframe)])\n",
    "                + \".csv\"\n",
    "            )\n",
    "            data.to_csv(newCsv_name, header=False)\n",
    "            break\n",
    " \n",
    "        row = Row(\n",
    "            date=base_data[timeframe[i]][0],\n",
    "            time=base_data[timeframe[i]][1],\n",
    "            p_open=float(base_data[timeframe[i]][2]),\n",
    "            p_high=getMax(base_data, 3, timeframe[i], timeframe[i + 1]),\n",
    "            p_low=getMin(base_data, 4, timeframe[i], timeframe[i + 1]),\n",
    "            p_close=float(base_data[(timeframe[i + 1]) - 1][5]),\n",
    "            volume=getSum(base_data, 6, timeframe[i], timeframe[i + 1]),\n",
    "            st_bullish=1\n",
    "            if float(base_data[(timeframe[i + 1]) - 1][5])\n",
    "            > float(base_data[timeframe[i]][2])\n",
    "            else 0,\n",
    "            st_bearish=1\n",
    "            if float(base_data[(timeframe[i + 1]) - 1][5])\n",
    "            < float(base_data[timeframe[i]][2])\n",
    "            else 0,\n",
    "            st_neutral=1\n",
    "            if float(base_data[(timeframe[i + 1]) - 1][5])\n",
    "            == float(base_data[timeframe[i]][2])\n",
    "            else 0,\n",
    "            ss_asia=1\n",
    "            if time.strptime(base_data[timeframe[i]][1], \"%H:%M\").tm_hour >= asia_start.tm_hour\n",
    "            and time.strptime(base_data[timeframe[i]][1], \"%H:%M\") < asia_end\n",
    "            else 0,\n",
    "            ss_europe=1\n",
    "            if time.strptime(base_data[timeframe[i]][1], \"%H:%M\").tm_hour >= europe_start.tm_hour\n",
    "            and time.strptime(base_data[timeframe[i]][1], \"%H:%M\") < europe_end\n",
    "            else 0,\n",
    "            ss_newyork=1\n",
    "            if time.strptime(base_data[timeframe[i]][1], \"%H:%M\").tm_hour >= newyork_start.tm_hour\n",
    "            and time.strptime(base_data[timeframe[i]][1], \"%H:%M\") < newyork_end\n",
    "            else 0,\n",
    "        )\n",
    "\n",
    "        data.append(row.makeRecord())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clrLists(timeframes):\n",
    "    for tf in timeframes:\n",
    "        tf.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1806/1465508064.py:34: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(\n",
      "/tmp/ipykernel_1806/1465508064.py:34: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "for sy in symbols:\n",
    "    clrLists(timeframes=timeframes)\n",
    "    base_data = processSymbol(sy)\n",
    "    makeTimeframeData(base_data=base_data)\n",
    "    for tf in timeframes:\n",
    "        # print(\"length of base_data :{}, symbol:{}\".format(str(len(base_data)), str(sy)))\n",
    "        # print(\"length of timeframe_data : {}\".format(str(len(tf))))\n",
    "        processCsv(base_data=base_data, timeframe=tf, symbol=sy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
